# End-to-End Spark with Docker & Jupyter

This project shows how to run **Apache Spark locally using Docker** and perform transformations on a sample dataset (`products.csv`).  
The setup uses **Docker Compose** with Jupyter Notebook for an interactive development experience.

---

## Project Overview
- Run Spark inside Docker using a pre-configured **docker-compose.yml**
- Use **Jupyter Notebook** as the coding interface
- Load and analyze the `products.csv` dataset
- Perform data exploration, cleaning, transformations, and aggregations in Spark

---
